{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7df34e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f2c9ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "upscaler = torch.hub.load(\n",
    "    'd:/nunif',            # đường dẫn repo local (hoặc 'nagadomi/nunif' trên GitHub)\n",
    "    'waifu2x',             # tên entry trong hubconf.py\n",
    "    source='local',        # 'local' = chạy repo clone, không cần internet\n",
    "\n",
    "    # ---- Tham số quan trọng ----\n",
    "    model_type='art_scan',      # kiểu model:\n",
    "                           #   'art'       = tranh, anime, chữ (OCR thường chọn cái này)\n",
    "                           #   'photo'     = ảnh chụp\n",
    "                           #   'art_scan'  = scan giấy/tài liệu\n",
    "\n",
    "    method='noise_scale',        # chế độ xử lý:\n",
    "                           #   'scale'        = chỉ phóng to\n",
    "                           #   'noise'        = chỉ khử nhiễu (không đổi size)\n",
    "                           #   'noise_scale'  = khử nhiễu + phóng to (thường dùng cho OCR)\n",
    "                           #   'auto_scale'   = tự động chọn scale theo input\n",
    "\n",
    "    noise_level=3,         # mức khử nhiễu:\n",
    "                           #   -1 = tắt\n",
    "                           #    0 = none/very low\n",
    "                           #    1 = low\n",
    "                           #    2 = medium\n",
    "                           #    3 = high\n",
    "\n",
    "    scale=2,               # hệ số phóng to:\n",
    "                           #   1 (no upscale), 1.6, 2, 4 (tuỳ model hỗ trợ)\n",
    "\n",
    "    # ---- Tối ưu hiệu năng ----\n",
    "    tile_size=64,         # chia ảnh thành tile 64/128/256/400/640 (VRAM thấp thì giảm)\n",
    "    batch_size=4,          # số tile xử lý song song (tăng khi có nhiều VRAM)\n",
    "    device_ids=[-1],       # [-1] = CPU, [0] = GPU0, [0,1] = multi-GPU\n",
    "    amp=True               # True = dùng FP16 (tăng tốc, giảm VRAM); chỉ hoạt động trên GPU NVIDIA\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f32569",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(r\"D:\\BData 2025\\n6_ocrmedical\\Requirement\\project\\img\\test0.jpeg\")        # RGBA cũng được\n",
    "out = upscaler(img)                  # chạy upscale + denoise\n",
    "out.save(r\"D:\\BData 2025\\n6_ocrmedical\\Requirement\\project\\img\\art_scan _output_test0.png\")\n",
    "print(\"Đã lưu thành công !\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
